\chapter{Background}
\label{cha:background}

This chapter establishes the theoretical foundations necessary for understanding the implementation and evaluation of an LLM-powered customer service assistant for e-commerce applications. We begin by examining the capabilities and limitations of Large Language Models in practical applications, followed by an analysis of the specific contextual requirements for e-commerce customer service automation. We then explore Retrieval Augmented Generation (RAG) techniques that enable LLMs to access external knowledge sources, and conclude with an overview of vector database technologies that provide the semantic search capabilities essential for efficient information retrieval in our system architecture.
\tdin{Check updates}

\section{Large Language Models}

Large Language Models (LLMs) are neural network architectures trained to understand and generate natural language responses. These models demonstrate strong performance across general knowledge tasks but require domain-specific context to be effectively applied in specialized applications such as e-commerce customer service.

The fundamental limitation of LLMs for practical applications lies in their training data cutoff and lack of access to real-time, business-specific information. While these models possess broad linguistic capabilities and general world knowledge, they cannot access current product catalogs, order statuses, or company-specific policies without external information retrieval mechanisms.

\section{Domain-Specific Context in the E-commerce Niche}

This thesis focuses on automating customer service responses that primarily involve retrieving and presenting existing information rather than executing transactional actions. The automated assistant is designed to handle informational queries by processing and presenting data already stored within the e-commerce system, emphasizing information delivery over system modifications or direct transaction processing.
In particular, three main categories of information are required to effectively respond to customer inquiries:
\begin{itemize}
    \item Order history information for questions regarding order status and contents
    \item Available product information to guide customers through the purchase process and provide relevant product recommendations
    \item E-commerce business rules including accepted payment methods, available delivery options, and courier information
\end{itemize}

\section{Retrieval Augmented Generation}
\label{sec:rag}

RAG is a technique that combines information retrieval with language generation to provide more accurate and contextual responses.
The implementation of RAG follows a straightforward process: when a user submits a query, the system first converts the query into a vector representation and searches a vector database for semantically similar content.
The most relevant information is then retrieved and provided as context to the LLM, which generates a response that incorporates this retrieved knowledge alongside its pre-trained capabilities.
This approach allows LLMs to access up-to-date, domain-specific information that wasn't present in their original training data.

\section{Vector Databases}
\label{sec:vecdb}

Vector databases are specialized storage systems designed to efficiently store and retrieve high-dimensional vector representations of data; in our case, for example, text embeddings generated by machine learning models.
They enable semantic search capabilities by measuring similarity between vectors, allowing systems to find contextually relevant information even when exact keyword matches don't exist.

\section{Prompt Engineering}
\label{sec:prompt-engineering}

Prompt engineering is the practice of designing and optimizing input prompts to guide LLM behavior and improve response quality.
Effective prompts provide clear instructions, appropriate context, and formatting guidelines that help the model generate more accurate and relevant responses.
In customer service applications, well-crafted prompts can significantly improve the consistency and helpfulness of automated responses by establishing the assistant's role, communication style, and response structure.
